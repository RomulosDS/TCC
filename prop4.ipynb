{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo TCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook foi executado no seguinte ambiente\n",
    "* Python 3.7.X\n",
    "* Jypyter Notebook 2.1.2\n",
    "* pandas 1.0.3\n",
    "* numpy 1.18.4\n",
    "\n",
    "Antes de executar verifique os requisitos acima e descomprima o arquivo <code>datasets_consolidados.zip</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega arquivos originais de temperatura e log de servidores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('datasets_consolidados/servidores-inlettemp.csv')\n",
    "logs = pd.read_csv('datasets_consolidados/logs_servidores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma amostra das bases de logs e temperatura de servidores em estado original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Server</th>\n",
       "      <th>Average</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>server01</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>Fri Dec 20 21:10:46 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>server01</td>\n",
       "      <td>-128</td>\n",
       "      <td>-128</td>\n",
       "      <td>Fri Dec 20 22:10:46 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>server01</td>\n",
       "      <td>-128</td>\n",
       "      <td>-128</td>\n",
       "      <td>Fri Dec 20 23:10:46 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>server01</td>\n",
       "      <td>-128</td>\n",
       "      <td>-128</td>\n",
       "      <td>Sat Dec 21 00:10:46 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>server01</td>\n",
       "      <td>-128</td>\n",
       "      <td>-128</td>\n",
       "      <td>Sat Dec 21 01:10:46 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541371</th>\n",
       "      <td>server30</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Thu Jan  2 06:01:57 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541372</th>\n",
       "      <td>server30</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Thu Jan  2 07:01:57 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541373</th>\n",
       "      <td>server30</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>Thu Jan  2 08:01:57 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541374</th>\n",
       "      <td>server30</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>Thu Jan  2 09:01:57 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541375</th>\n",
       "      <td>server30</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Thu Jan  2 10:01:57 2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1541376 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Server  Average  Peak                      Time\n",
       "0        server01       21    22  Fri Dec 20 21:10:46 2013\n",
       "1        server01     -128  -128  Fri Dec 20 22:10:46 2013\n",
       "2        server01     -128  -128  Fri Dec 20 23:10:46 2013\n",
       "3        server01     -128  -128  Sat Dec 21 00:10:46 2013\n",
       "4        server01     -128  -128  Sat Dec 21 01:10:46 2013\n",
       "...           ...      ...   ...                       ...\n",
       "1541371  server30       19    20  Thu Jan  2 06:01:57 2020\n",
       "1541372  server30       19    20  Thu Jan  2 07:01:57 2020\n",
       "1541373  server30       19    21  Thu Jan  2 08:01:57 2020\n",
       "1541374  server30       18    21  Thu Jan  2 09:01:57 2020\n",
       "1541375  server30       19    20  Thu Jan  2 10:01:57 2020\n",
       "\n",
       "[1541376 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica a quantidade de linhas com valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Server     0\n",
       "Average    0\n",
       "Peak       0\n",
       "Time       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Server</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Date</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>server01</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fri Dec 20 2013 20:15:46</td>\n",
       "      <td>Log cleared.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>server01</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Mon Mar 31 2014 14:24:53</td>\n",
       "      <td>The power input for power supply 2 is lost.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>server01</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Mon Mar 31 2014 14:25:04</td>\n",
       "      <td>Power supply redundancy is lost.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>server01</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Mon Mar 31 2014 13:29:08</td>\n",
       "      <td>The input power for power supply 2 has been re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>server01</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Mon Mar 31 2014 13:29:13</td>\n",
       "      <td>The power supplies are redundant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6363</th>\n",
       "      <td>server30</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Tue May 21 2019 13:35:57</td>\n",
       "      <td>Power supply redundancy is lost.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6364</th>\n",
       "      <td>server30</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Tue May 21 2019 20:05:01</td>\n",
       "      <td>The input power for power supply 2 has been re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6365</th>\n",
       "      <td>server30</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Tue May 21 2019 20:05:07</td>\n",
       "      <td>The power supplies are redundant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6366</th>\n",
       "      <td>server30</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Sun Jul 28 2019 06:42:53</td>\n",
       "      <td>The power input for power supply 1 is lost.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6367</th>\n",
       "      <td>server30</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Sun Jul 28 2019 06:42:56</td>\n",
       "      <td>Power supply redundancy is lost.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6368 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Server  Severity                      Date  \\\n",
       "0     server01    Normal  Fri Dec 20 2013 20:15:46   \n",
       "1     server01  Critical  Mon Mar 31 2014 14:24:53   \n",
       "2     server01  Critical  Mon Mar 31 2014 14:25:04   \n",
       "3     server01    Normal  Mon Mar 31 2014 13:29:08   \n",
       "4     server01    Normal  Mon Mar 31 2014 13:29:13   \n",
       "...        ...       ...                       ...   \n",
       "6363  server30  Critical  Tue May 21 2019 13:35:57   \n",
       "6364  server30    Normal  Tue May 21 2019 20:05:01   \n",
       "6365  server30    Normal  Tue May 21 2019 20:05:07   \n",
       "6366  server30  Critical  Sun Jul 28 2019 06:42:53   \n",
       "6367  server30  Critical  Sun Jul 28 2019 06:42:56   \n",
       "\n",
       "                                            Description  \n",
       "0                                          Log cleared.  \n",
       "1           The power input for power supply 2 is lost.  \n",
       "2                      Power supply redundancy is lost.  \n",
       "3     The input power for power supply 2 has been re...  \n",
       "4                     The power supplies are redundant.  \n",
       "...                                                 ...  \n",
       "6363                   Power supply redundancy is lost.  \n",
       "6364  The input power for power supply 2 has been re...  \n",
       "6365                  The power supplies are redundant.  \n",
       "6366        The power input for power supply 1 is lost.  \n",
       "6367                   Power supply redundancy is lost.  \n",
       "\n",
       "[6368 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Server         0\n",
       "Severity       0\n",
       "Date           0\n",
       "Description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove as não-ocorrências de temperatura, ou seja, o servidor está desligado e isso é evidenciado com o atributo <code>Average</code> com valor de <code>-128</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.drop(temp.index[temp['Average'] == -128], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforma o atributo <code>Time</code> em tipo Date and cria um atributo <code>DateOnly</code> para posteriores comparações entre bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['Time']= pd.to_datetime(temp['Time'], format=\"%a %b %d %H:%M:%S %Y\")\n",
    "temp['DateOnly'] = temp['Time'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordena a base de temperaturas em função do nome do servidor e do dia/hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.sort_values(by=['Server', 'Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupa as linhas em função do nome de servidor e data, sumariza atráves do agrupamento os atributos <code>Average</code> e <code>Peak</code> com informações de Minímo, Máximo, Média, Mediana, Variância e Desvio Padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_summary = temp.groupby(['Server','DateOnly'])[['Average','Peak']].agg(['min', 'max','mean','median','var','std']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A operação de groupby adiciona uma nova linha de indíces, pra isso é necessário realizar um ajuste para se manter uma só linha de índice sem perda de identidade das colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_summary.columns = [\"_\".join(x) for x in temp_summary.columns.ravel()]\n",
    "temp_summary.rename(columns={'Server_':'Server','DateOnly_':'DateOnly'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove as ocorrências da base de logs aonde a data tem formato inválido pois indica o System Boot da máquina e transforma o atributo <code>Date</code> em tipo Date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.drop(logs.index[logs['Date'] == 'System Boot'], inplace = True)\n",
    "logs['Date']= pd.to_datetime(logs['Date'], format=\"%a %b %d %Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria o atributo <code>DateOnly</code> e orderna a base de logs em função do nome do servidor e o dia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logs['DateOnly'] = logs['Date'].dt.date\n",
    "logs.sort_values(by=['Server', 'Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combina as duas bases em uma só usando como índice o nome do servidor e o dia. Para cada ocorrência de log será concatenado os atributos de temperatura do servidor no dia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged2 = pd.merge(temp_summary,logs, on=['Server', 'DateOnly'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitui o valores vazios (ausência de registro de log) da coluna <code>Severity</code> com o valor <code>Normal</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged2.Severity.fillna(\"NoneAlert\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adiciona o atributo categórico <code>TempSala</code> que indica se a sala de servidores estava quente, esquentando ou fria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged2.loc[merged2['Peak_max'] <= 26, 'TempSala'] = 'SalaFria'\n",
    "merged2.loc[(merged2['Peak_max'] > 26) & (merged2['Peak_max'] <= 33), 'TempSala'] = 'SalaEsquentando'\n",
    "merged2.loc[merged2['Peak_max'] > 33, 'TempSala'] = 'SalaQuente'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amostra da base combinada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O atributo Severity será útil ao executar alguns modelos como o PCA na base merged, mas a maioria dos modelos requer que atributos categoricos sejam transformados em inteiros. Para isso, utilizaremos a técnica de One-Hot Encoding para isso.\n",
    "\n",
    "Abaixo podemos visualizar os possíveis valores para Severity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged2.Severity.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria-se um dataset com os valores possíveis e utilizamos a função pd.get_dummies() para gerar as colunas numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Severity': ['NoneAlert','Normal', 'Critical', 'Warning']})\n",
    "merged2 = pd.concat([merged2,pd.get_dummies(merged2['Severity'], prefix='Severity')],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma amostra dos novos atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged2.filter(regex=(\"Severity_*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporta as bases para CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp.to_csv(r'datasets_consolidados/temperatura.csv', index = False) # export all datasets\n",
    "#logs.to_csv(r'datasets_consolidados/logs.csv', index = False)\n",
    "#merged.to_csv(r'datasets_consolidados/merged.csv', index = False)\n",
    "merged2.to_csv(r'datasets_consolidados/merged2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando dados com PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequência de atributos importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "Severity = sns.countplot(merged2['Severity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TempSala = sns.countplot(merged2['TempSala'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostra a matriz de correlação entre os atributos núméricos. Cores quentes (vermelho) indicam uma correlação positiva, cores frias (azul) indicam uma correlação negativa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "corrs = merged2.corr()\n",
    "mask = np.zeros_like(corrs)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corrs, cmap='Spectral_r', mask=mask, square=True, vmin=-.4, vmax=.4)\n",
    "plt.title('Matriz de Correlação')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando a temperatura Média (min/max) e Picos (min/max) como features e normalizando os valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Average_max','Average_mean','Peak_max']\n",
    "# Separating out the features\n",
    "x = merged2.loc[:, features].values\n",
    "# Separating out the target\n",
    "y = merged2.loc[:,['Severity']].values\n",
    "\n",
    "x = StandardScaler().fit_transform(x)\n",
    "pd.DataFrame(data = x, columns = features).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executar o PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "principalDf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset com os componentes e o target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = pd.concat([principalDf, merged2[['Severity']]], axis = 1)\n",
    "finalDf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotando o gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 Component PCA', fontsize = 20)\n",
    "\n",
    "\n",
    "targets = [ 'NoneAlert','Normal', 'Warning','Critical']\n",
    "colors = [ 'b','g', 'y','r']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['Severity'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando base de treino e teste 70% treino e 30% teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaliza os atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roda o classificador de árvore de decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
